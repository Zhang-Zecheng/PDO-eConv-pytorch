{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  对于PDO_eConvs的简易复现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据集 Rotated Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rotated_mnist(batch_size):\n",
    "    #导入数据，将.amat格式转换为numpy array\n",
    "    data_train = np.loadtxt('C:\\\\Users\\\\roderickzzc\\\\Desktop\\\\project\\\\pdo-ecov\\\\mnist_rotation_new\\\\mnist_all_rotation_normalized_float_train_valid.amat')\n",
    "    data_test = np.loadtxt('C:\\\\Users\\\\roderickzzc\\\\Desktop\\\\project\\\\pdo-ecov\\\\mnist_rotation_new\\\\mnist_all_rotation_normalized_float_test.amat')\n",
    "\n",
    "    # get train image datas\n",
    "    x_train_val = data_train[:, :-1] / 1.0\n",
    "    #由于原始数据集默认为784*1，现改为28*28\n",
    "    x_train_val=np.reshape(x_train_val,(12000,1,28,28))\n",
    "    x_test = data_test[:, :-1] / 1.0\n",
    "    x_test=np.reshape(x_test,(50000,1,28,28))\n",
    "    # get train image labels\n",
    "    y_train_val = data_train[:, -1:]\n",
    "    y_test = data_test[:, -1:]\n",
    "    print(x_train_val[0].shape)\n",
    "    \n",
    "    # pytorch data loader\n",
    "    #根据论文抽取2000个样本from training set作为validation\n",
    "    train_val = torch.utils.data.TensorDataset(torch.Tensor(x_train_val), torch.Tensor(y_train_val))\n",
    "    train, val = torch.utils.data.random_split(train_val, [10000,2000])\n",
    "    test = torch.utils.data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "    ## feature, label = train[0]\n",
    "    ## print(feature.shape, label) \n",
    "    train_iter = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_iter = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "\n",
    "\n",
    "    return train_iter, val_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "train_iter, val_iter, test_iter = load_rotated_mnist(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义PDO_conv2D的Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_dict_0 = torch.tensor([[[0,0,0,0,0],[0,0,0,0,0],[0,0,1,0,0],[0,0,0,0,0],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[0,0,0,0,0],[0,-1/2,0,1/2,0],[0,0,0,0,0],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[0,0,1/2,0,0],[0,0,0,0,0],[0,0,-1/2,0,0],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[0,0,0,0,0],[0,1,-2,1,0],[0,0,0,0,0],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[0,-1/4,0,1/4,0],[0,0,0,0,0],[0,1/4,0,-1/4,0],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[0,0,1,0,0],[0,0,-2,0,0],[0,0,1,0,0],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[0,0,0,0,0],[-1/2,1,0,-1,1/2],[0,0,0,0,0],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[0,1/2,-1,1/2,0],[0,0,0,0,0],[0,-1/2,1,-1/2,0],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[0,-1/2,0,1/2,0],[0,1,0,-1,0],[0,-1/2,0,1/2,0],[0,0,0,0,0]],\n",
    "                    [[0,0,1/2,0,0],[0,0,-1,0,0],[0,0,0,0,0],[0,0,1,0,0],[0,0,-1/2,0,0]],\n",
    "                    [[0,0,0,0,0],[0,0,0,0,0],[1,-4,6,-4,1],[0,0,0,0,0],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[-1/4,1/2,0,-1/2,1/4],[0,0,0,0,0],[1/4,-1/2,0,1/2,-1/4],[0,0,0,0,0]],\n",
    "                    [[0,0,0,0,0],[0,1,-2,1,0],[0,-2,4,-2,0],[0,1,-2,1,0],[0,0,0,0,0]],\n",
    "                    [[0,-1/4,0,1/4,0],[0,1/2,0,-1/2,0],[0,0,0,0,0],[0,-1/2,0,1/2,0],[0,1/4,0,-1/4,0]],\n",
    "                    [[0,0,1,0,0],[0,0,-4,0,0],[0,0,6,0,0],[0,0,-4,0,0],[0,0,1,0,0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=8\n",
    "group_angle = [2*k*pi/p+pi/8 for k in range(p)]\n",
    "tran_to_partial_coef_0 = [torch.tensor([[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                                     [0,cos(x),sin(x),0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                                     [0,-sin(x),cos(x),0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                                     [0,0,0,pow(cos(x),2),2*cos(x)*sin(x),pow(sin(x),2),0,0,0,0,0,0,0,0,0],\n",
    "                                     [0,0,0,-cos(x)*sin(x),pow(cos(x),2)-pow(sin(x),2),sin(x)*cos(x),0,0,0,0,0,0,0,0,0],\n",
    "                                     [0,0,0,pow(sin(x),2),-2*cos(x)*sin(x),pow(cos(x),2),0,0,0,0,0,0,0,0,0],\n",
    "                                     [0,0,0,0,0,0,-pow(cos(x),2)*sin(x),pow(cos(x),3)-2*cos(x)*pow(sin(x),2),-pow(sin(x),3)+2*pow(cos(x),2)*sin(x), pow(sin(x),2)*cos(x),0,0,0,0,0],\n",
    "                                     [0,0,0,0,0,0,cos(x)*pow(sin(x),2),-2*pow(cos(x),2)*sin(x)+pow(sin(x),3),pow(cos(x),3)-2*cos(x)*pow(sin(x),2),sin(x)*pow(cos(x),2),0,0,0,0,0],\n",
    "                                     [0,0,0,0,0,0,0,0,0,0,pow(sin(x),2)*pow(cos(x),2),-2*pow(cos(x),3)*sin(x)+2*cos(x)*pow(sin(x),3),pow(cos(x),4)-4*pow(cos(x),2)*pow(sin(x),2)+pow(sin(x),4),-2*cos(x)*pow(sin(x),3)+2*pow(cos(x),3)*sin(x),pow(sin(x),2)*pow(cos(x),2)]]).to('cuda') for x in group_angle]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coef(weight,num_inputs,num_outputs):\n",
    "        #weight.size 1,7,3,3 or 56,7,3,3\n",
    "        \n",
    "        transformation = partial_dict_0[[0,1,2,3,4,5,7,8,12],1:4,1:4] #9*3*3\n",
    "        transformation = transformation.view([9,9])\n",
    "        transformation = transformation.to('cuda')\n",
    "        #print('transformation',transformation.device)\n",
    "        inv_transformation = transformation.inverse()#inverse matrix\n",
    "        \n",
    "        betas = torch.reshape(weight,(-1,9))#56*7*9\n",
    "        betas = betas.to('cuda')\n",
    "        betas = torch.mm(betas,inv_transformation)# 56*7*9\n",
    "        betas = torch.reshape(betas,(num_inputs,num_outputs,9))\n",
    "        \n",
    "        #print('betas',betas.device)\n",
    "        return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z2_kernel(weight,num_inputs,num_outputs,p,partial,tran):\n",
    "    og_coef = torch.reshape(weight,(num_inputs*num_outputs,9)) #(56*7)*9\n",
    "    #print('og',og_coef.type())\n",
    "    partial_coef = [torch.mm(og_coef,a) for a in tran]#8,(56*7)*15\n",
    "    partial = torch.reshape(partial,(15,25))#15*25\n",
    "    partial=partial.to('cuda')\n",
    "    \n",
    "    kernel = [torch.mm(a,partial) for a in partial_coef]#8,(56*7)*25\n",
    "    kernel = torch.stack(kernel,dim=1)#(56*7)*8*25\n",
    "    kernel = torch.reshape(kernel,(num_outputs*p,num_inputs,5,5))#56*56*5*5 or 56*1*5*5\n",
    "    #kernel=kernel.to('cuda')\n",
    "    #print('z2kernel',kernel.device)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class open_conv2d(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs,p,partial,tran):\n",
    "        super().__init__()\n",
    "        self.p=p\n",
    "        self.num_inputs=num_inputs\n",
    "        self.num_outputs=num_outputs\n",
    "        self.partial=partial\n",
    "        self.tran=tran\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.Tensor(self.num_inputs,self.num_outputs,3,3))\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "    def forward(self, input):\n",
    "        \n",
    "        betas=get_coef(self.weight,self.num_inputs,self.num_outputs)\n",
    "        \n",
    "        kernel=z2_kernel(betas,self.num_inputs,self.num_outputs,self.p,self.partial,self.tran)\n",
    "        \n",
    "         \n",
    "\n",
    "        input_shape = input.size()#input_size: 128,1,h,w & 128,56,h,w\n",
    "        input = input.view(input_shape[0], self.num_inputs, input_shape[-2], input_shape[-1])\n",
    "        \n",
    "        #y_size: 128,56,h,w\n",
    "        \n",
    "        outputs = F.conv2d(input, weight=kernel, bias=None, stride=1,\n",
    "                        padding=1)\n",
    "\n",
    "        batch_size, _, ny_out, nx_out = outputs.size()\n",
    "        outputs = outputs.view(batch_size, self.num_outputs*self.p, ny_out, nx_out)\n",
    "        #y_size: 128,7*8,h,w\n",
    "\n",
    "\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class g_bn(nn.Module):\n",
    "    def __init__(self,p):\n",
    "        super(g_bn, self).__init__()\n",
    "        self.p=p\n",
    "        self.bn=nn.BatchNorm2d(7)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        channel,height,width = list(inputs.size())[1:]\n",
    "        inputs = inputs.view(-1,int(channel/p),p,height,width)\n",
    "        inputs = inputs.view(-1,int(channel/p),height*p,width)\n",
    "        \n",
    "        outputs=self.bn(inputs)\n",
    "        \n",
    "        outputs=outputs.view(-1,int(channel/p),p,height,width,)\n",
    "        outputs = outputs.view(-1,channel,height,width)\n",
    "        \n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class g_conv2d(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs,p,partial,tran):\n",
    "        super().__init__()\n",
    "        self.p=p\n",
    "        self.num_inputs=int(num_inputs/p)\n",
    "        self.num_outputs=num_outputs\n",
    "        self.partial=partial\n",
    "        self.tran=tran\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.Tensor(self.p*self.num_inputs,self.num_outputs,3,3))\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "    def forward(self, input):\n",
    "        \n",
    "        #print(self.weight.size())\n",
    "        betas=get_coef(self.weight,self.num_inputs*self.p,self.num_outputs)\n",
    "        og_coef = betas.view(self.num_inputs*self.p*self.num_outputs,9)#(56*7)，9\n",
    "        \n",
    "        tran_to_partial_coef = self.tran #8，9*15\n",
    "        partial_coef = [torch.mm(og_coef,a) for a in tran_to_partial_coef] #8，（56*7）*15\n",
    "\n",
    "        \n",
    "        partial_dict = self.partial\n",
    "        partial_dict = partial_dict.view(15,25)#15*25\n",
    "        partial_dict = partial_dict.to('cuda')\n",
    "        \n",
    "\n",
    "        og_kernel_list = [torch.mm(a,partial_dict) for a in partial_coef] #8，（56*7）*25\n",
    "        og_kernel_list = [og_kernel.view(self.num_inputs,self.p,self.num_outputs,25) for og_kernel in og_kernel_list] #8，（7*8*7*25）\n",
    "        \n",
    "        #print(og_kernel_list[0][:,0:,:].size(),og_kernel_list[0][:,:0,:].size())\n",
    "        og_kernel_list = [torch.cat([og_kernel_list[k][:,-k:,:],og_kernel_list[k][:,:-k,:]],dim=1) for k in range(p)] #8，（7*8*7*25）\n",
    "        \n",
    "        \n",
    "        kernel = torch.stack(og_kernel_list,dim=3)#7,8,7,8,25\n",
    "        kernel = kernel.view(self.num_inputs*self.p,self.num_outputs*self.p,5,5)#56,56,5,5\n",
    "          \n",
    "        \n",
    "        outputs = F.conv2d(input, weight=kernel, bias=None, stride=1,\n",
    "                        padding=1)\n",
    "        batch_size, _, ny_out, nx_out = outputs.size()\n",
    "        outputs = outputs.view(batch_size, self.num_outputs*self.p, ny_out, nx_out)\n",
    "        #y_size: 128,7*8,h,w\n",
    "        \n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P8_PDO_Conv_Z2(open_conv2d):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(P8_PDO_Conv_Z2, self).__init__(num_inputs=1, num_outputs=7,p=8,partial=partial_dict_0,tran=tran_to_partial_coef_0)\n",
    "\n",
    "\n",
    "class P8_PDO_Conv_P8(g_conv2d):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(P8_PDO_Conv_P8, self).__init__(num_inputs=56, num_outputs=7,p=8,partial=partial_dict_0,tran=tran_to_partial_coef_0)\n",
    "\n",
    "class BN_P8(g_bn):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(BN_P8, self).__init__(p=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义PDO_eConvs神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDO_eConvs(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PDO_eConvs, self).__init__()\n",
    "        self.conv1 = P8_PDO_Conv_Z2(1,7,8)\n",
    "        self.conv2 = P8_PDO_Conv_P8(56,7,8)\n",
    "        self.conv3 = P8_PDO_Conv_P8(56,7,8)\n",
    "        self.conv4 = P8_PDO_Conv_P8(56,7,8)\n",
    "        self.conv5 = P8_PDO_Conv_P8(56,7,8)\n",
    "        self.conv6 = P8_PDO_Conv_P8(56,7,8)\n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "        self.bn1 = BN_P8(8)\n",
    "        self.bn2 = BN_P8(8)\n",
    "        self.bn3 = BN_P8(8)\n",
    "        self.bn4 = BN_P8(8)\n",
    "        self.bn5 = BN_P8(8)\n",
    "        self.bn6 = BN_P8(8)\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(4*4*7*8, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        \n",
    "        x = self.dropout(self.bn1(F.relu(self.conv1(x))))\n",
    "        #print(x.size())\n",
    "        x = self.maxpool2(self.bn2(F.relu(self.conv2(x))))\n",
    "        \n",
    "        x = self.dropout(self.bn3(F.relu(self.conv3(x))))\n",
    "        x = self.dropout(self.bn4(F.relu(self.conv4(x))))\n",
    "        x = self.dropout(self.bn5(F.relu(self.conv5(x))))\n",
    "        x = self.dropout(self.bn6(F.relu(self.conv6(x))))\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        y=torch.nn.functional.log_softmax(x)\n",
    "\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-659b75651d94>:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "net=PDO_eConvs()\n",
    "\n",
    "net.apply(init_weights)\n",
    "#device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X = X.to(device)\n",
    "            #print(X.type(),X.size())\n",
    "            y=y.view(1,-1)[0]\n",
    "            y=y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                \n",
    "                #print(net(X.to(device)).argmax(dim=1))\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: \n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    batch_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            #print(X.type(),X.size())\n",
    "            y=y.view(1,-1)[0]\n",
    "            y=y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            #print(y.type(),y.size())\n",
    "            y_hat = net(X)\n",
    "            \n",
    "            #print(y_hat.type(),y_hat.size())\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            #print('a',net.conv1.weight.grad)\n",
    "            l.backward()\n",
    "            \n",
    "            #print('b',net.conv1.weight.grad)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        \n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-c76085c9d52b>:36: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y=torch.nn.functional.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0724, train acc 0.976, test acc 0.960, time 31.3 sec\n",
      "epoch 2, loss 0.0379, train acc 0.973, test acc 0.959, time 30.9 sec\n",
      "epoch 3, loss 0.0237, train acc 0.976, test acc 0.961, time 30.2 sec\n",
      "epoch 4, loss 0.0181, train acc 0.975, test acc 0.958, time 28.9 sec\n",
      "epoch 5, loss 0.0141, train acc 0.975, test acc 0.962, time 27.9 sec\n",
      "epoch 6, loss 0.0119, train acc 0.977, test acc 0.960, time 28.4 sec\n",
      "epoch 7, loss 0.0100, train acc 0.975, test acc 0.959, time 28.2 sec\n",
      "epoch 8, loss 0.0084, train acc 0.978, test acc 0.961, time 28.2 sec\n",
      "epoch 9, loss 0.0081, train acc 0.976, test acc 0.961, time 28.2 sec\n",
      "epoch 10, loss 0.0072, train acc 0.976, test acc 0.960, time 28.2 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.0001, 10\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
